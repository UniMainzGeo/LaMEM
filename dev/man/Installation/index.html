<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Installation · LaMEM</title><meta name="title" content="Installation · LaMEM"/><meta property="og:title" content="Installation · LaMEM"/><meta property="twitter:title" content="Installation · LaMEM"/><meta name="description" content="Documentation for LaMEM."/><meta property="og:description" content="Documentation for LaMEM."/><meta property="twitter:description" content="Documentation for LaMEM."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../Home/">LaMEM</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../Home/">Home</a></li><li><a class="tocitem" href="../Quickstart/">Quick start</a></li><li><span class="tocitem">User Guide</span><ul><li class="is-active"><a class="tocitem" href>Installation</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#1.0-Precompiled-binaries"><span>1.0 Precompiled binaries</span></a></li><li class="toplevel"><a class="tocitem" href="#1.1-Installation-from-source"><span>1.1 Installation from source</span></a></li><li><a class="tocitem" href="#1.1.1-Prerequisites"><span>1.1.1 Prerequisites</span></a></li><li><a class="tocitem" href="#1.1.2-Automated-PETSc-installation-using-Spack"><span>1.1.2 Automated PETSc installation using Spack</span></a></li><li><a class="tocitem" href="#1.1.3-Manual-PETSc-installation"><span>1.1.3 Manual PETSc installation</span></a></li><li><a class="tocitem" href="#1.1.4-Installing-PETSc-on-a-cluster"><span>1.1.4 Installing PETSc on a cluster</span></a></li><li><a class="tocitem" href="#1.1.5-Download-and-compile-LaMEM"><span>1.1.5 Download and compile LaMEM</span></a></li><li class="toplevel"><a class="tocitem" href="#1.2.-Visualization"><span>1.2. Visualization</span></a></li></ul></li><li><a class="tocitem" href="../GettingStarted/">Getting Started</a></li><li><a class="tocitem" href="../InitialModelSetup/">Initial Model setup</a></li></ul></li><li><span class="tocitem">Development</span><ul><li><a class="tocitem" href="../LaMEM_Development/">LaMEM Development</a></li><li><a class="tocitem" href="../Debugging/">LaMEM Debugging</a></li></ul></li><li><a class="tocitem" href="../CODE_OF_CONDUCT/">Code of conduct</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>Installation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Installation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/UniMainzGeo/LaMEM" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/UniMainzGeo/LaMEM/blob/master/docs/src/man/Installation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h1><h1 id="1.0-Precompiled-binaries"><a class="docs-heading-anchor" href="#1.0-Precompiled-binaries">1.0 Precompiled binaries</a><a id="1.0-Precompiled-binaries-1"></a><a class="docs-heading-anchor-permalink" href="#1.0-Precompiled-binaries" title="Permalink"></a></h1><p>The absolute simplest way to get LaMEM working on your system is to download pre-compiled libraries which are available for over 100 architectures and systems, including essentially all systems in use at the moment. You can install it through the julia package manager, and you can run it either through julia or through the terminal (after setting the correct path):</p><pre><code class="language-julia hljs">julia&gt; ]
pkg&gt; add LaMEM
pkg&gt; test LaMEM</code></pre><p>More details are given <a href="https://github.com/JuliaGeodynamics/LaMEM.jl">here</a>. This will work fine on your local machine or server (including in parallel). Yet, if you are planning to use LaMEM on large parallel HPC clusters you (or your system administrator) may still need to compile PETSc.</p><h1 id="1.1-Installation-from-source"><a class="docs-heading-anchor" href="#1.1-Installation-from-source">1.1 Installation from source</a><a id="1.1-Installation-from-source-1"></a><a class="docs-heading-anchor-permalink" href="#1.1-Installation-from-source" title="Permalink"></a></h1><p>LaMEM is build in top of <a href="http://www.mcs.anl.gov/petsc/">PETSc</a>, which provides great support for parallel solvers and grid infrastructure. Different than other codes used in geodynamics, LaMEM does not require an excessive amount of additional packages, except for the ones that can be downloaded through the PETSc installation system. </p><p>This installation guide was created based on initial input from Giovanni Mainetti and Andrea Bistacchi (University of Milano Bicocca), with input from the Mainz team (Andrea Picollo, Boris Kaus).</p><p>The LaMEM development team uses different approaches internally, and over years many aspects of installing PETSc and using LaMEM become easier. Yet if you ask us now (october 2020), what we recommend when you are a new user it would be the following:</p><ol><li><a href="http://www.mcs.anl.gov/petsc/download/index.html">PETSc</a> using the correct version, including the external packages SUPERLU_DIST, MUMPS, PASTIX and UMFPACK (Suitesparse). These are all direct solvers that we use for 2D simulations, or as coarse grid solvers, so they are useful to have. If you happen to have compilation errors with some of them (e.g., mumps), it is also ok to only have one direct solver.</li><li>Python (3+ is best), to run the LaMEM testing suite. </li><li><a href="https://code.visualstudio.com">Microsoft Visual Studio Code</a>, which is by far the best debugger/development environment at the moment. Useful plugins: <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode.cpptools">C/C++ with Intellisense</a> (debugging LaMEM code), <a href="https://marketplace.visualstudio.com/items?itemName=ms-python.python">Python</a>, <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh">Remote SSH</a> (great if you want to change LaMEM inut scripts on a remote server)</li><li><a href="https://www.paraview.org">Paraview</a> for visualizations.   </li></ol><h2 id="1.1.1-Prerequisites"><a class="docs-heading-anchor" href="#1.1.1-Prerequisites">1.1.1 Prerequisites</a><a id="1.1.1-Prerequisites-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.1-Prerequisites" title="Permalink"></a></h2><p>We have tested LaMEM on Linux, Mac and Windows 10. The development team uses Mac and Linux, so these machines are best supported. As Windows 10 now has a (still experimental) bash shell (called WLS), you can install PETSc within this shell by following the Linux installation instructions.</p><h2 id="1.1.2-Automated-PETSc-installation-using-Spack"><a class="docs-heading-anchor" href="#1.1.2-Automated-PETSc-installation-using-Spack">1.1.2 Automated PETSc installation using Spack</a><a id="1.1.2-Automated-PETSc-installation-using-Spack-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.2-Automated-PETSc-installation-using-Spack" title="Permalink"></a></h2><p>The most complicated step in getting LaMEM running is to install the correct version of PETSc, on your laptop or cluster. Below we give more specific info if you want to do it yourself on Mac or Linux.  Yet, an alternative and newer method to install PETSc and all required compilers on a new (linux/mac) machine or even on a complicated cluster is <a href="https://spack.io">spack</a>. It installs everything required and consistently with the same compilers in a separate directory and works quite well in our experience (including installing additional packages).  A spack tutorial can be found <a href="https://spack-tutorial.readthedocs.io/en/latest/">here</a>. </p><p><em>Brief instructions:</em> You can install spack in your home directory with:</p><pre><code class="nohighlight hljs">$ git clone https://github.com/spack/spack.git ~/spack
$ cd ~/spack</code></pre><p>And add environmental variables:</p><pre><code class="nohighlight hljs">$ . share/spack/setup-env.sh </code></pre><p>Find the compilers you have</p><pre><code class="nohighlight hljs">$ spack compilers</code></pre><p>Get info about the PETSc package that you can install:</p><pre><code class="nohighlight hljs">$ spack info petsc</code></pre><p>Install PETSc with the correct packages, and leave out stuff we don&#39;t need. The optimized compilation of PETSc is installed with</p><pre><code class="nohighlight hljs">$ spack install petsc@3.22.5 +mumps +suite-sparse -hypre -hdf5 -shared -debug</code></pre><p>If that works out, you&#39;ll have to update your environmental variables and create the <span>$PETSC_OPT$</span> variable</p><pre><code class="nohighlight hljs">$ . share/spack/setup-env.sh 
$ export PETSC_OPT=$(spack location -i petsc)       </code></pre><p>You would have to redo the same for a debug version of PETSc to hve the full compilation up and running. </p><h2 id="1.1.3-Manual-PETSc-installation"><a class="docs-heading-anchor" href="#1.1.3-Manual-PETSc-installation">1.1.3 Manual PETSc installation</a><a id="1.1.3-Manual-PETSc-installation-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.3-Manual-PETSc-installation" title="Permalink"></a></h2><p>The alterative method is to install PETSc yourself. That is a bit more effort, but also enables you to install packages (like Pastix), that are not available in the spack distribution. Below we have installation instructions for Mac and Linux. On Windows, uses the WSL and follow the linux instructions.</p><h3 id="1.1.3.1-Mac"><a class="docs-heading-anchor" href="#1.1.3.1-Mac">1.1.3.1 Mac</a><a id="1.1.3.1-Mac-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.3.1-Mac" title="Permalink"></a></h3><p>On Mac, you will need to ensure that Xcode and the Xcode command line tools are installed. It is also a good idea to install compilers and MPI using a package manager. One possibility is to install MacPorts, and install compilers with:</p><pre><code class="nohighlight hljs">$ sudo port install gcc7</code></pre><p>and make it the default compilers</p><pre><code class="nohighlight hljs">$ sudo port select --set gcc gcc7</code></pre><p>Next, install the MPI library MPICH with:</p><pre><code class="nohighlight hljs">$ sudo port install mpich-gcc7-fortran</code></pre><p>and make it the default with</p><pre><code class="nohighlight hljs">$ sudo port select --set mpi mpich-gcc7-fortran</code></pre><p>You may easily have several other compilers installed on your Mac. For a correct installation of PETSc, you will need to ensure that all compilers point to the correct version (in the example above, gcc7 installed from MacPorts). Test this with</p><pre><code class="nohighlight hljs">$ mpif90 --version
$ mpicc --version</code></pre><h3 id="1.1.3.2-Linux"><a class="docs-heading-anchor" href="#1.1.3.2-Linux">1.1.3.2 Linux</a><a id="1.1.3.2-Linux-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.3.2-Linux" title="Permalink"></a></h3><p>These instructions have been tested with Ubuntu. Make sure that your packages are installed correctly and are up to date, with:</p><pre><code class="nohighlight hljs">$ sudo apt update</code></pre><p>If needed, update all outdated packages with</p><pre><code class="nohighlight hljs">$ sudo apt dist-upgrade</code></pre><h3 id="1.1.3.3-Python"><a class="docs-heading-anchor" href="#1.1.3.3-Python">1.1.3.3 Python</a><a id="1.1.3.3-Python-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.3.3-Python" title="Permalink"></a></h3><p>Make sure that both python 3.0 and python 2.7 is installed, for example by typing </p><pre><code class="nohighlight hljs">$ which python</code></pre><p>If it is not installed, change that which can be done on Linux with:</p><pre><code class="nohighlight hljs">sudo apt install python2.7 python-pip</code></pre><p>or on Mac, for example, by installing the <a href="https://anaconda.org">anaconda</a> package. Alternatively, you can install the <a href="https://www.macports.org">Macports</a> package manager and install it with</p><pre><code class="nohighlight hljs">sudo port install python27</code></pre><h3 id="1.1.3.4-Compilers-and-various-other-packages"><a class="docs-heading-anchor" href="#1.1.3.4-Compilers-and-various-other-packages">1.1.3.4 Compilers and various other packages</a><a id="1.1.3.4-Compilers-and-various-other-packages-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.3.4-Compilers-and-various-other-packages" title="Permalink"></a></h3><p>PETSc will need fortran and C compilers. Which fortran compiler you use is not all that important, so you are welcome to use gcc and gfortran. Once you are a more experienced LaMEM user and do production runs, you might want to try different options to see if this speeds up the simulations. In addition to the compilers, it is a good idea to install git and cmake as well. </p><p>On linux this can be done with</p><pre><code class="nohighlight hljs">$ sudo apt update
$ sudo apt install gfortran gcc git cmake</code></pre><p>and on Mac, using macports</p><pre><code class="nohighlight hljs">$ sudo port selfupdate
$ sudo port install gfortran gcc git cmake</code></pre><h3 id="1.1.3.5-PETSc"><a class="docs-heading-anchor" href="#1.1.3.5-PETSc">1.1.3.5 PETSc</a><a id="1.1.3.5-PETSc-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.3.5-PETSc" title="Permalink"></a></h3><p>The most important package for LaMEM is PETSc. If you just want to give LaMEM a try, the most basic installation is sufficient. Once you do production runs, it is worthwhile to experiment a bit with more optimized solver options. Installing PETSc with those does not always work, but PETSc has a very responsive user list which is searchable, and where you can post your questions if needed.  As PETSc regularly changes its syntac, LaMEM is always only compatible with a particular version of PETSc. This is typically updated once per year. </p><p>The current version of LaMEM is compatible with <strong>PETSc 3.22.5</strong>  We have also successfully compiled LaMEM with PETSc 3.23.x so you are also welcome to use that, but our Github actions CI testing environment uses 3.22.5 at the moment. </p><p>You can download the PETSc version you need <a href="http://www.mcs.anl.gov/petsc/download/index.html">here</a>. Do that and unzip it with</p><pre><code class="nohighlight hljs">$ tar -xvf petsc-3.22.5.tar.gz</code></pre><p>Change to the PETSc directory from the command window, for example with:</p><pre><code class="nohighlight hljs">$ cd ~/Software/PETSc/petsc-3.22.5</code></pre><p>and specify the PETSC environmental variable:</p><pre><code class="nohighlight hljs">$ export PETSC_DIR=$PWD</code></pre><p>The simplest installation of PETSc can be configured as follows (assuming you are in the PETSc directory). This will automatically download and install the MPI library as well, together with a few other packages we will use.</p><pre><code class="nohighlight hljs">$  ./config/configure.py --prefix=/opt/petsc/petsc-3.22.5-opt --download-mpich=1 --download-superlu_dist=1 --download-mumps=1 --download-scalapack=1 --download-fblaslapack=1 --with-debugging=0 --FOPTFLAGS=-O3 --CXXOPTFLAGS=-O3 --COPTFLAGS=-O3 --with-shared-libraries=0 --download-cmake</code></pre><p>This will install an optimized (fast) version of PETSc on your system in the directory <code>opt/petsc/petsc-3.22.5-opt</code>. You can change this directory, obviously, but in that case please remember where you put it as we need it later.</p><p>If you want to have more control over PETSc and use the MPI version that you installed earlier on your system, using the package manager (see above), you can install it as: </p><pre><code class="nohighlight hljs">$ ./config/configure.py --prefix=/opt/petsc/petsc-3.22.5-opt --download-superlu_dist=1 --doCleanup=1 --download-mumps=1 --download-suitesparse=1 --download-scalapack=1 --download-fblaslapack=1  --FOPTFLAGS=-O3 --CXXOPTFLAGS=-O3 --COPTFLAGS=-O3 --with-shared-libraries=0 --download-cmake --with-debugging=0 --with-mpi-include=/opt/local/include/mpich-gcc7/ --with-cc=/opt/local/bin/mpicc --with-cxx=/opt/local/bin/mpicxx --with-fc=/opt/local/bin/mpif90 --with-mpi-lib=/opt/local/lib/mpich-gcc7/libmpi.a</code></pre><p>Note that the above lines assume that mpi is installed under the directory <code>/opt/local/bin/</code>.  You can check that this is the case for you as well by typing</p><pre><code class="nohighlight hljs">$ which mpiexec</code></pre><p>which should give you the dirtectory <code>/opt/local/bin/mpiexec</code>. If it gives you a different directory, you will have to use that directory in the PETSc configuration listed above.  Both methods discussed above will install the parallel direct solvers MUMPS and SUPERLU_DIST. LaMEM will also work without these parallel solvers, but we find them particularly useful for 2D simulations and as coarse grid solvers.</p><p>After the configuration step has finished succesfully (which will take some time), it should look something like <img src="../../assets/img/PETSc_configure.png" alt="Configure PETSc"/></p><p>Next, make PETSc with:</p><pre><code class="nohighlight hljs">$ make PETSC_DIR=/Users/kausb/Software/PETSC/petsc-3.22.5 PETSC_ARCH=arch-darwin-c-opt all</code></pre><p>After that, you will be asked to install PETSc </p><pre><code class="nohighlight hljs">sudo make PETSC_DIR=/Users/kausb/Software/PETSC/petsc-3.22.5 PETSC_ARCH=arch-darwin-c-opt install</code></pre><p>and test whether the installation works with</p><pre><code class="nohighlight hljs">$ make PETSC_DIR=/opt/petsc/petsc-3.22.5-opt PETSC_ARCH=&quot;&quot; check</code></pre><p>This will run a few test cases and if all is well, will tell you so.</p><p>If you only run simulations with LaMEM, the optimized version of PETSc described above will be sufficient. Yet, if you also develop routines and have to do debugging, it is a good idea to also install the debug version:</p><pre><code class="nohighlight hljs">$ ./config/configure.py --prefix=/opt/petsc/petsc-3.22.5-deb --download-superlu_dist=1 --doCleanup=1 --download-mumps=1 --download-suitesparse=1 --download-scalapack=1 --download-fblaslapack=1 --FOPTFLAGS=&quot;-O0 -g&quot; --CXXOPTFLAGS=&quot;-O0 -g&quot; --COPTFLAGS=&quot;-O0 -g&quot; --with-shared-libraries=0 --download-cmake --with-debugging=1 --with-mpi-include=/opt/local/include/mpich-gcc7/ --with-cc=/opt/local/bin/mpicc --with-cxx=/opt/local/bin/mpicxx --with-fc=/opt/local/bin/mpif90 --with-mpi-lib=/opt/local/lib/mpich-gcc7/libmpi.a</code></pre><p>Compared to before, we have three changes, namely: </p><ol><li>That the prefix (or the directory where PETSc will be put) is changed to <code>--prefix=/opt/petsc/petsc-3.22.5-deb</code> </li><li>We tell it to compile a debug version of PETSc with  <code>--with-debugging=1</code></li><li>We change the optimization flags to <code>--FOPTFLAGS=&quot;-O0 -g&quot; --CXXOPTFLAGS=&quot;-O0 -g&quot; --COPTFLAGS=&quot;-O0 -g&quot;</code></li></ol><p>With this you can repeat the procedure above. Just for completion, the simple configute option of above in debug mode would thus be:</p><pre><code class="nohighlight hljs">$  ./config/configure.py --prefix=/opt/petsc/petsc-3.22.5-deb --download-mpich=1 --download-superlu_dist=1 --download-mumps=1 --download-scalapack=1 --download-fblaslapack=1 --download-cmake --with-debugging=1 --FOPTFLAGS=&quot;-O0 -g&quot; --CXXOPTFLAGS=&quot;-O0 -g&quot; --COPTFLAGS=&quot;-O0 -g&quot; --with-shared-libraries=0</code></pre><h2 id="1.1.4-Installing-PETSc-on-a-cluster"><a class="docs-heading-anchor" href="#1.1.4-Installing-PETSc-on-a-cluster">1.1.4 Installing PETSc on a cluster</a><a id="1.1.4-Installing-PETSc-on-a-cluster-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.4-Installing-PETSc-on-a-cluster" title="Permalink"></a></h2><p>Chances exists that you want to install PETSc on a cluster. The main point to take into account is that you need to link it against the appropriate MPI compilers. </p><p>If you are lucky, a previous version of PETSc exists already on the cluster and you want to reinstall it in your home directory while adding some new packages such as SUPERLU_DIST or MUMPS. In that case, there is simple trick to find out the exact options that were used to compile PETSc on the cluster: </p><ol><li>Compile one of the PETSc examples, for example <code>ex1</code> in the PETSc directory under <code>/src/ksp/ksp/examples/tutorials</code></li><li>Run it, while adding the command-line option <code>-log_view</code></li><li>At the end of the simulation, it will show you the command-line options that were used to compile PETSc. These can be long; for us it was:</li></ol><pre><code class="nohighlight hljs">Configure options: --prefix=/cluster/easybuild/broadwell/software/numlib/PETSc/3.22.5-intel-2018.02-downloaded-deps --with-mkl_pardiso=1 --with-mkl_pardiso-dir=/cluster/easybuild/broadwell/software/numlib/imkl/2018.2.199-iimpi-2018.02-GCC-6.3.0/mkl --with-hdf5=1 --with-hdf5-dir=/cluster/easybuild/broadwell/software/data/HDF5/1.8.20-intel-2018.02 --with-large-io=1 --with-c++-support=1 --with-debugging=0 --download-hypre=1 --download-triangle=1 --download-ptscotch=1 --download-pastix=1 --download-ml=1 --download-superlu=1 --download-metis=1 --download-superlu_dist=1 --download-prometheus=1 --download-mumps=1 --download-parmetis=1 --download-suitesparse=1 --download-hypre-shared=0 --download-metis-shared=0 --download-ml-shared=0 --download-mumps-shared=0 --download-parmetis-shared=0 --download-pastix-shared=0 --download-prometheus-shared=0 --download-ptscotch-shared=0 --download-suitesparse-shared=0 --download-superlu-shared=0 --download-superlu_dist-shared=0 --with-cc=mpiicc --with-cxx=mpiicpc --with-c++-support --with-fc=mpiifort --CFLAGS=&quot;-O3 -xCORE-AVX2 -ftz -fp-speculation=safe -fp-model source -fPIC&quot; --CXXFLAGS=&quot;-O3 -xCORE-AVX2 -ftz -fp-speculation=safe -fp-model source -fPIC&quot; --FFLAGS=&quot;-O2 -xCORE-AVX2 -ftz -fp-speculation=safe -fp-model source -fPIC&quot; --with-gnu-compilers=0 --with-mpi=1 --with-build-step-np=4 --with-shared-libraries=1 --with-debugging=0 --with-pic=1 --with-x=0 --with-windows-graphics=0 --with-fftw=1 --with-fftw-include=/cluster/easybuild/broadwell/software/numlib/imkl/2018.2.199-iimpi-2018.02-GCC-6.3.0/mkl/include/fftw --with-fftw-lib=&quot;[/cluster/easybuild/broadwell/software/numlib/imkl/2018.2.199-iimpi-2018.02-GCC-6.3.0/mkl/lib/intel64/libfftw3xc_intel_pic.a,libfftw3x_cdft_lp64_pic.a,libmkl_cdft_core.a,libmkl_blacs_intelmpi_lp64.a,libmkl_intel_lp64.a,libmkl_sequential.a,libmkl_core.a]&quot; --with-scalapack=1 --with-scalapack-include=/cluster/easybuild/broadwell/software/numlib/imkl/2018.2.199-iimpi-2018.02-GCC-6.3.0/mkl/include --with-scalapack-lib=&quot;[/cluster/easybuild/broadwell/software/numlib/imkl/2018.2.199-iimpi-2018.02-GCC-6.3.0/mkl/lib/intel64/libmkl_scalapack_lp64.a,libmkl_blacs_intelmpi_lp64.a,libmkl_intel_lp64.a,libmkl_sequential.a,libmkl_core.a]&quot; --with-blaslapack-lib=&quot;[/cluster/easybuild/broadwell/software/numlib/imkl/2018.2.199-iimpi-2018.02-GCC-6.3.0/mkl/lib/intel64/libmkl_intel_lp64.a,libmkl_sequential.a,libmkl_core.a]&quot; --with-hdf5=1 --with-hdf5-dir=/cluster/easybuild/broadwell/software/data/HDF5/1.8.20-intel-2018.02</code></pre><ol><li>Use the same options for your latest installation, while adding config options you may need.</li></ol><h2 id="1.1.5-Download-and-compile-LaMEM"><a class="docs-heading-anchor" href="#1.1.5-Download-and-compile-LaMEM">1.1.5 Download and compile LaMEM</a><a id="1.1.5-Download-and-compile-LaMEM-1"></a><a class="docs-heading-anchor-permalink" href="#1.1.5-Download-and-compile-LaMEM" title="Permalink"></a></h2><p>Once you successfully installed the correct version of PETSc, installing LaMEM should be straightforward. You can download the latest version of LaMEM with</p><pre><code class="nohighlight hljs">git clone https://github.com/UniMainzGeo/LaMEM.git ./LaMEM</code></pre><p>Next you need to specify the environmental variables <code>PETSC_OPT</code> and <code>PETSC_DEB</code>:</p><pre><code class="nohighlight hljs">export PETSC_OPT=/opt/petsc/petsc-3.22.5-opt
export PETSC_DEB=/opt/petsc/petsc-3.22.5-deb</code></pre><p>Note that this may need to be adapted, depending on the machine you use. You may also want to specify this in your <code>.bashrc</code> files.</p><p>Next you can install an optimized version of LaMEM by going to the <code>/src</code> directory in the LaMEM directory, and typing:</p><pre><code class="nohighlight hljs">make mode=opt all</code></pre><p>At the end of the installation, it should look like: <img src="../../assets/img/Installation_CompileLaMEM.png" alt="Installation_LaMEM"/></p><p>Similarly, you can install a debug version of LaMEM with</p><pre><code class="nohighlight hljs">make mode=deb all</code></pre><p>The binaries are located in: </p><pre><code class="nohighlight hljs">/LaMEM/bin/opt/LaMEM
/LaMEM/bin/deb/LaMEM</code></pre><p>You have succesfully installed LaMEM and should try if everything works correctly by running the tests:</p><pre><code class="nohighlight hljs">$cd ../tests
$make test</code></pre><p>The first time you do this, it will download the python package <a href="https://bitbucket.org/dmay/pythontestharness/src/master/">pyTestHarness</a>, by Dave May and Patrick Sanan, which we use for testing. If it fails to download it autimatically, you may have to download it manually.</p><p>Next, we start the python script <code>runLaMEM_tests.py</code> which runs the test-suite. The summary at the end should only show passed tests.</p><p>If this works, we are ready to run a first simulation. Navigate to the following directory:</p><pre><code class="nohighlight hljs">$cd ../input_models/BuildInSetups</code></pre><p>The <code>*.dat</code> files in that directory (list them with typing <code>ls</code> on the command-line) are standard LaMEM input files. To start a simulation the only thing to do is to call the code:</p><pre><code class="nohighlight hljs">$mpiexec -n 1 ../../bin/opt/LaMEM -ParamFile FallingSpheres_Multigrid.dat </code></pre><p>which should looke like: <img src="../../assets/img/Installation_FirstRun.png" alt="Installation_FirstRun"/></p><h1 id="1.2.-Visualization"><a class="docs-heading-anchor" href="#1.2.-Visualization">1.2. Visualization</a><a id="1.2.-Visualization-1"></a><a class="docs-heading-anchor-permalink" href="#1.2.-Visualization" title="Permalink"></a></h1><p>The output of LaMEM is in VTK format, which can be read and visualized with any software that can handle this filetype. For us, the our choice of code is <a href="http://paraview.org/">Paraview</a>, which is very well maintained package that runs on all systems, and even allows you to do parallel rendering. We usually simply download the binaries from the webpage. If you want to render on a large-scale cluster instead, we recommend that you buy your system administrator a beer.</p><p>After opening, paraview looks like this:</p><p><img src="../../assets/img/Paraview_opening.png" alt="Paraview 5.4"/></p><p>You can open a LaMEM simulation by opening the *.pvd files in the directory from where you started the simulation. Hitting the &quot;play&quot; button will show you an animation of all available timesteps.</p><h3 id="1.2.1.-Linux-Graphics-card"><a class="docs-heading-anchor" href="#1.2.1.-Linux-Graphics-card">1.2.1. Linux - Graphics card</a><a id="1.2.1.-Linux-Graphics-card-1"></a><a class="docs-heading-anchor-permalink" href="#1.2.1.-Linux-Graphics-card" title="Permalink"></a></h3><p>Having the correct graphics card is important to have Paraview run efficiently and create output. Paraview will also run without graphics card, but not quite as smoothly. These instructions apply to workstations with Nvidia graphic cards. To check if your Nvidia driver is updated, type:</p><pre><code class="nohighlight hljs">$ ubuntu-drivers devices</code></pre><p>This results in a list of devices where you should see your Nvidia graphic card and drivers, e.g.:</p><pre><code class="nohighlight hljs">$ == /sys/devices/pci0000:00/0000:00:05.0/0000:02:00.0 ==
$ modalias : pci:v000010DEd00001180sv00001043sd0000842Ebc03sc00i00
$ vendor   : NVIDIA Corporation
$ model    : GK104 [GeForce GTX 680]
$ driver   : nvidia-340 - distro non-free
$ driver   : nvidia-driver-396 - third-party free recommended
$ driver   : nvidia-driver-390 - third-party free
$ driver   : nvidia-304 - third-party free
$ driver   : xserver-xorg-video-nouveau - distro free builtin</code></pre><p>To install the recommended driver for your card, type:</p><pre><code class="nohighlight hljs">$ sudo ubuntu-drivers autoinstall</code></pre><p>Alternatively to install a specific driver (e.g. nvidia-340):</p><pre><code class="nohighlight hljs">$ sudo apt install nvidia-340</code></pre><p>Then reboot to use the new driver.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Quickstart/">« Quick start</a><a class="docs-footer-nextpage" href="../GettingStarted/">Getting Started »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.15.0 on <span class="colophon-date" title="Friday 31 October 2025 12:44">Friday 31 October 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
