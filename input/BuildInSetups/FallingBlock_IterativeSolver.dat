# This shows a simple falling block example in non-dimensional units, solved with an iterative solver.
# This will work on any PETSc installation (even without MUMPS/SUPERLU_DIST) in serial and parallel.
#
# Linear viscosity is assumed.
# It runs for 10 timesteps and creates output every timestep.
#
# Assuming that you are in /input_models/BuildInSetups, you run it with:
#	../../bin/opt/LaMEM -ParamFile FallingBlock_IterativeSolver.dat
#
# or, in parallel:
#	mpiexec -n 4 ../../bin/opt/LaMEM -ParamFile FallingBlock_IterativeSolver.dat
#
# Output can be visualized by using Paraview to open 
#	FB_iterative.pvd 	    -> Velocity, viscosity etc.
#	FB_iterative_phase.pvd 	-> Compositional field @ a higher resolution
#
# Note that we do not recommend this for the general case; instead we suggest that you
# install PETSc with SUPERLU_DIT and MUMPS
#
# Have a look at FallingBlock_DirectSolver.dat for an example.

#===============================================================================
# Scaling
#===============================================================================

	units = none		# non-dimensional units

#===============================================================================
# Time stepping parameters
#===============================================================================

	time_end  = 100   # simulation end time
	dt        = 10    # time step
	dt_min    = 1e-5  # minimum time step (declare divergence if lower value is attempted)
	dt_max    = 100   # maximum time step
	dt_out    = 0.2   # output step (output at least at fixed time intervals)
	inc_dt    = 0.1   # time step increment per time step (fraction of unit)
	CFL       = 0.5   # CFL (Courant-Friedrichs-Lewy) criterion
	CFLMAX    = 0.5   # CFL criterion for elasticity
	nstep_max = 10    # maximum allowed number of steps (lower bound: time_end/dt_max)
	nstep_out = 1000  # save output every n steps
	nstep_rdb = 0     # save restart database every n steps


#===============================================================================
# Grid & discretization parameters
#===============================================================================

# Number of cells for all segments

	nel_x = 16
	nel_y = 16
	nel_z = 16

# Coordinates of all segments (including start and end points). Domain size

	coord_x = 0.0 1.0
	coord_y = 0.0 1.0
	coord_z = 0.0 1.0

#===============================================================================
# Free surface
#===============================================================================

# Default

#===============================================================================
# Boundary conditions
#===============================================================================

# Default

#===============================================================================
# Solution parameters & controls
#===============================================================================

	gravity        = 0.0 0.0 -1.0   # gravity vector (acting in z-direction)
	FSSA           = 1.0            # free surface stabilization parameter [0 - 1]
	init_guess     = 0              # initial guess flag
	eta_min        = 1e-3           # viscosity lower bound
	eta_max        = 1e12           # viscosity upper limit

#===============================================================================
# Solver options
#===============================================================================
	SolverType 		=	direct 			# solver [direct or multigrid] - note that this is overwritten below
	
		
#===============================================================================
# Model setup & advection
#===============================================================================

	msetup         = geom              # setup type
	nmark_x        = 3                 # markers per cell in x-direction
	nmark_y        = 3                 # ...                 y-direction
	nmark_z        = 3                 # ...                 z-direction
	bg_phase       = 0                 # background phase ID
	rand_noise     = 1                 # random noise flag
	advect         = rk2               # advection scheme
	interp         = stagp             # velocity interpolation scheme
	stagp_a        = 0.7               # STAG_P velocity interpolation parameter
	mark_ctrl      = avd               # marker control type
	nmark_lim      = 16 100            # min/max number per cell
	

# Geometric primitives:

#	<BoxStart>
#		phase  = 1
#		bounds = 0.25 0.75 0.25 0.75 0.25 0.75  # (left, right, front, back, bottom, top)
#	<BoxEnd>

	<HexStart>
		phase  = 1
		coord = 0.25 0.25 0.25   0.75 0.25 0.25   0.75 0.75 0.25   0.25 0.75 0.25   0.25 0.25 0.75   0.75 0.25 0.75   0.75 0.75 0.75   0.25 0.75 0.75
	<HexEnd>

#===============================================================================
# Output
#===============================================================================

# Grid output options (output is always active)

	out_file_name       = FB_iterative # output file name
	out_pvd             = 1       	# activate writing .pvd file

# AVD phase viewer output options (requires activation)

	out_avd     = 1 # activate AVD phase output
	out_avd_pvd = 1 # activate writing .pvd file
	out_avd_ref = 3 # AVD grid refinement factor

#===============================================================================
# Material phase parameters
#===============================================================================

	# Define properties of matrix
	<MaterialStart>
		ID  = 0 # phase id
		rho = 1 # density
		eta = 1 # viscosity
	<MaterialEnd>

	# Define properties of block
	<MaterialStart>
		ID  = 1   # phase id
		rho = 2   # density
		eta = 100 # viscosity
	<MaterialEnd>

#===============================================================================
# PETSc options
#===============================================================================

<PetscOptionsStart>

	# LINEAR & NONLINEAR SOLVER OPTIONS
	-snes_type ksponly # no nonlinear solver

	-js_ksp_monitor # display how the inner iterations converge

	# override the direct solver with an iterative solver (note that we do 
	# not recommend this for production runs, but that this works on serial and parallel 
	# with a basic PETSc installation that does not have external packages installed).
	# For real work, we recommend installing at least MUMPS and SUPERLU_DIST with PETSc
	-js_pc_type bjacobi
	
	

<PetscOptionsEnd>

#===============================================================================
